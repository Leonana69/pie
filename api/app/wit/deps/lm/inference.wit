interface inference {

  allocate: func(count:u32) -> list<u32>;
  deallocate: func(ids: list<u32>);

  fill-blocks: func(blocks:list<u32>, context: list<u32>, inputs: list<u32>, outputs: list<u32>);
  copy-block: func(src:u32, dst:u32, src-offset:u32, dst-offset:u32, size:u32);
  mask-block: func(block:u32, mask:list<u32>);

  export-blocks: func(src:list<u32>, name:string);
  import-blocks: func(dst:list<u32>, name:string);

  embed-text: func(embs:list<u32>, tokens:list<u32>);
  embed-image: func(embs:list<u32>, url:string);
  embed-video: func(embs:list<u32>, url:string);

  decode-token-dist: func(embs:list<u32>, dist:list<u32>);
  sample-top-k: func(embs:list<u32>, k:u32) -> list<u32>;
  get-token-dist: func(dist:u32) -> list<f32>;

  tokenize: func(text:string) -> list<u32>;
  detokenize: func(tokens:list<u32>) -> string;

  // use kvcache.{block-list, mask, sink};
  //
  // resource token-distribution {
  //   sample-p: func() -> u32;
  //   top-k: func(k: u32) -> list<u32>;
  // }
  //
  // resource language-model {
  //   constructor(model-id:string);
  //   tokenize: func(text: string) -> list<u32>;
  //   detokenize: func(tokens: list<u32>) -> string;
  //
  //   // for indices, we could use RLE-like encoding to compress the list.
  //   // dist-n is the number of distributions to return.
  //   predict-all: func(blocks: block-list, tokens: list<u32>, indices: list<u32>, mask:mask, sink:sink, dist-n:u32) -> list<token-distribution>;
  // }
}

//
//
// interface kvcache {
//
//   variant mask {
//     none,
//     block-indices(list<u32>),
//     block-range(tuple<u32, u32>),
//   }
//
//
//   //
//   resource input-embedding {
//     constructor(embedding: list<input-embedding>);
//     length: func() -> u32;
//     extend: func(embedding: input-embedding);
//     slice: func(range: tuple<u32, u32>) -> input-embedding;
//     pad: func(length: u32);
//   }
//
//   resource output-embedding {
//     constructor(embedding: list<output-embedding>);
//     length: func() -> u32;
//     extend: func(embedding: output-embedding);
//     slice: func(range: tuple<u32, u32>) -> output-embedding;
//     next-token-distribution: func() -> list<distribution>;
//     // aggregate: func() -> feature;
//   }
//
//   embed-tokens: func(tokens: list<u32>, positions: list<u32>) -> input-embedding;
//   embed-string: func(text: string, position-offset: u32) -> input-embedding;
//   embed-image: func(url: string, position-offset: u32) -> input-embedding;
//   embed-sound: func(url: string, position-offset: u32) -> input-embedding;
//
//   resource context-block {
//     // keeps block_id internally.
//     fill: func(ctx:context, input: embedding, mask:mask, retain-output:bool);
//     empty: func(range: tuple<u32, u32>);
//     copy: func(other:block, src-range:tuple<u32, u32>, dest-range:tuple<u32, u32>);
//     output-embedding: func(range: tuple<u32, u32>) -> output-embedding;
//     drop-output-embedding: func();
//   }
//
//   // this is actually a set. The order is just for indexing purposes. So this is more like a ranged map.
//   // RLE-like encoding could be used to compress the list.
//   // This is only needed to avoid WASM-host boundary crosssing.
//   resource context {
//     constructor(blocks: list<context-block>);
//     length: func() -> u32;
//     append: func(block: context-block);
//     remove: func(block: context-block);
//     extend: func(ctx: context);
//     slice: func(range: tuple<u32, u32>) -> context;
//     index: func(position: u32) -> context-block;
//     clone: func() -> context;
//   }
//
//   // return "initialized" block handles (block id reserved after 2^18)]
//   allocate-context: func(block-count:u32) -> context;
//   allocate-context-block: func() -> context-block;
//
//   free-context: func(ctx: context);
//   free-context-block: func(block: context-block);
//
//   available-context-blocks: func() -> u32;
//
//   //
//   //
//   // // a single cached token
//   // resource token {
//   //    position: func() -> u32;
//   //    token-id: func() -> u32;
//   // }
//   //
//   // // a sequence of cached tokens
//   // resource token-list {
//   //
//   //   // the list could be empty
//   //   constructor(tokens: list<token>);
//   //
//   //   // mutating methods
//   //   push: func(token: token);
//   //   pop: func() -> token;
//   //   extend: func(tokens: token-list);
//   //   splice: func(start: u32, delete-count: u32, tokens: token-list);
//   //
//   //   // non-mutating methods
//   //   length: func() -> u32;
//   //   slice: func(start: u32, end: u32) -> token-list;
//   //   concat: func(cache: token-list) -> token-list;
//   //   index: func(position: u32) -> token;
//   //
//   // }
// }