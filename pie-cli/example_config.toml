# Sample config.toml
host = "127.0.0.1"
port = 8080
enable_auth = true
auth_secret = "hello"
verbose = true
log = "pie.log"

[[backend]]
backend_type = "python"
exec_path = "../backend/backend-python/server.py"
model = "llama-3.2-1b-instruct"
device = "cuda:0"
dtype = "bfloat16"
kv_page_size = 32
dist_size = 8
max_num_kv_pages = 1000
max_num_embeds = 50000
